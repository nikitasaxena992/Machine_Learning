{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikitasaxena992/Machine_Learning/blob/main/Tweet_Topic_Identifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NKXUAj3ljysc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08a169d-726d-457c-ab5b-882f24b6e45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "model = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)\n",
        "from statistics import mean\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarityCalculator:\n",
        "  def __init__(self, text, df):\n",
        "    self.text = text\n",
        "    self.df = df\n",
        "    self.text_embedded = self.get_msg_embedded([text])\n",
        "    self.keyword_embedded = self.get_embedded_dict(df[\"keyword\"])\n",
        "    self.topic_embedded = self.get_embedded_dict(df[\"topic\"])\n",
        "\n",
        "  def get_embedded_dict(self, data):\n",
        "    dict_embedded = {}\n",
        "    for words in data:\n",
        "      word = words.split(\",\")\n",
        "      for key in word:\n",
        "        stripped_key = key.strip()\n",
        "        if stripped_key not in dict_embedded:\n",
        "          dict_embedded[stripped_key] = self.get_msg_embedded([stripped_key])\n",
        "    return dict_embedded\n",
        "\n",
        "  def get_msg_embedded(self, input):\n",
        "    return model(input)\n",
        "\n",
        "  def similarity_measure_with_text(self, word_embedded):\n",
        "    distance = scipy.spatial.distance.cdist(self.text_embedded, word_embedded, \"cosine\")[0]\n",
        "    return (1-distance)[0]\n",
        "\n",
        "  def get_similarity_from_keyword(self, df):\n",
        "    data_max = []\n",
        "    data_avg = []\n",
        "    for keywords in df['keyword']:\n",
        "      similarity_measure_list=[]\n",
        "      keyword = keywords.split(\",\")\n",
        "      for word in keyword:\n",
        "        stripped_keyword = word.strip()\n",
        "        key_emb = self.keyword_embedded[stripped_keyword]\n",
        "        similarity_measure_list.append(self.similarity_measure_with_text(key_emb))\n",
        "      data_max.append(max(similarity_measure_list))\n",
        "      data_avg.append(mean(similarity_measure_list))\n",
        "    return data_max, data_avg\n",
        "\n",
        "  def get_similarity_from_topic(self, df):\n",
        "    data = []\n",
        "    for topic in df['topic']:\n",
        "      topic_emb = self.topic_embedded[topic]\n",
        "      data.append(self.similarity_measure_with_text(topic_emb))\n",
        "    return data\n",
        "\n",
        "  @staticmethod\n",
        "  def get_clean_text_keywords(text):\n",
        "    # For tweets we will need to remove hyperlinks, @mentions, any punctuations and non alphanumeric characters.\n",
        "    text = re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)',' ',text)\n",
        "    ps = PorterStemmer()\n",
        "    text = [ps.stem(word) for word in text.lower().split() if word not in set(stopwords.words('english'))]\n",
        "    text = list(set(text))\n",
        "    return text\n",
        "\n",
        "  def get_similarity_of_topic_by_direct_matching(self, df):\n",
        "    direct_matching_topic = []\n",
        "    for topic in df['topic']:\n",
        "      if topic in SimilarityCalculator.get_clean_text_keywords(self.text):\n",
        "        direct_matching_topic.append(1)\n",
        "      else:\n",
        "        direct_matching_topic.append(0)\n",
        "    \n",
        "    return direct_matching_topic\n",
        "\n",
        "    \n",
        "  def get_similarity_of_keyword_by_direct_matching(self, df):\n",
        "    direct_matching_keyword = []\n",
        "    for keyword in df['keyword']:\n",
        "      sum_matching_keys = 0\n",
        "      for key in list(set(keyword.split(\",\"))):\n",
        "          if key.strip() in SimilarityCalculator.get_clean_text_keywords(self.text):\n",
        "            sum_matching_keys += 1\n",
        "      direct_matching_keyword.append(sum_matching_keys)\n",
        "    return direct_matching_keyword\n"
      ],
      "metadata": {
        "id": "pTCfi5Xyg4AU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-restful \n",
        "!pip install flask-ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I9YtU6-OIdW",
        "outputId": "f4267e29-5389-46af-91e8-1e4a5f2dc465"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-restful\n",
            "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask-restful) (2022.6)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-restful) (1.1.4)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from flask-restful) (1.15.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-restful) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-restful) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-restful) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-restful) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-restful) (2.0.1)\n",
            "Installing collected packages: aniso8601, flask-restful\n",
            "Successfully installed aniso8601-9.0.1 flask-restful-0.3.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from flask import Flask, jsonify, request\n",
        "\n",
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "!ngrok authtoken '2HSKbKu8Xk9hQ1H4BInJMBqgGqK_27gzegbTMUCqG3Wvj1ce1'\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "\n",
        "# on the terminal type: curl http://127.0.0.1:5000/\n",
        "# returns hello world when we use GET.\n",
        "# returns the data that we send when we use POST.\n",
        "@app.route('/', methods = ['GET', 'POST'])\n",
        "def home():\n",
        "    if(request.method == 'GET'):\n",
        "     df = pd.read_csv(\"/content/Topic Data.csv\")\n",
        "     text = [\"In the Super 12 stage of this #T20WorldCup   , 99 bowlers were used. The highest Bowling Impact recorded was that of Anrich Nortje, reaching a vast +88. The second lowest was Kagiso Rabada, on -39.\",\n",
        "        \"#BREAKING - Liquorgate Case: Manish Sisodia aide Dinesh Arora turns approver.#ManishSisodia\",\n",
        "        \"For us this world cup is like 2011 ODI World Cup. For Pakistan it's like 2017 CT or 1992 WC. And for England and New Zealand it's like 2019 ODI world cup\",\n",
        "        \"Countries with most Men's Player of the Month awards Five different players won it for India (Pant, Ashwin, Bhuvi, Shreyas, Kohli).\",\n",
        "        \"PM Modi is now speaking for himself, not speaking for people as some outside force but speaking as one of the people who has been successful, that is very threatening to the intellectuals\",\n",
        "        \"EXCLUSIVE: #RanveerSingh and #Shankar to team up on the biggest Pan Indian Cinematic event - #Shankar to direct #Ranveer in a 3-part film based on the iconic #Velpari Novel. Filming begins in 2023. Read more details\",\n",
        "        \"UK Court approves extradition of Robert Vadra’s aide, Sanjay Bhandari, who is facing ED, CBI probe in PMLA case in India\",\n",
        "        \"Gujarat elections: Can PM Modi bank on Gujarati pride again? Watch the panelists discuss on #TTP with \",\n",
        "        \"Massive support for the BJP across Gujarat. Watch from Kaprada.\",\n",
        "        \"Dev Diwali is special and Dev Diwali in Kashi is even more memorable. Have a look at these magnificent pictures from the eternal city of Kashi…\",\n",
        "        \"JUST IN - Elon Musk urges independent voters to cast ballots for Republicans in the U.S. midterm election.\"]\n",
        "\n",
        "    text=[\"I like to roam around a lot, yesterday I went to Mountains. cruise\"]\n",
        "    text_df = pd.DataFrame(text, columns=['text'])\n",
        "    text_df\n",
        "    final_df = pd.DataFrame(columns=['text', \"topic\", \"keyword\", \"topic_text_similarity\", \"keyword_max\",  \"keyword_avg\", \"direct_matching_keyword\", \"direct_matching_topic\"])\n",
        "\n",
        "    for text in text_df[\"text\"]:\n",
        "        sm_calculator = SimilarityCalculator(text, df)\n",
        "\n",
        "        # Get topic text similarity\n",
        "        topic_similarity = sm_calculator.get_similarity_from_topic(df)\n",
        "\n",
        "        # Get max and average of keyword text similarity\n",
        "        keyword_max, keyword_avg = sm_calculator.get_similarity_from_keyword(df)\n",
        "\n",
        "        # Get similarity by direct matching of keywords\n",
        "        direct_matching_keyword = sm_calculator.get_similarity_of_keyword_by_direct_matching(df)\n",
        "\n",
        "        # Get similarity by direct matching of topics\n",
        "        direct_matching_topic = sm_calculator.get_similarity_of_topic_by_direct_matching( df)\n",
        "\n",
        "        #Assign all values to df\n",
        "        df[\"text\"] = text\n",
        "        \n",
        "        df[\"topic_text_similarity\"] = topic_similarity\n",
        "        df[\"keyword_max\"] = keyword_max\n",
        "        df[\"keyword_avg\"] = keyword_avg\n",
        "        df[\"direct_matching_keyword\"] = direct_matching_keyword\n",
        "        df[\"direct_matching_topic\"] = direct_matching_topic\n",
        "        final_df = final_df.append(df, ignore_index = True)\n",
        "\n",
        "        final_df= final_df.sort_values('topic_text_similarity',ascending=False)\n",
        "\n",
        "\n",
        "    def word_avg(topic_text_simi,keywrd_max,keywrd_avg,direct_match_keyword,direct_match_topic):\n",
        "        topic_text_simi = 30* topic_text_simi\n",
        "        keywrd_max = 30 * keywrd_max\n",
        "        keywrd_avg = 20* keywrd_avg\n",
        "\n",
        "        if direct_match_keyword > 1:\n",
        "            direct_match_keyword =  10 * 1.5\n",
        "\n",
        "        else:\n",
        "            direct_match_keyword = direct_match_keyword* 10\n",
        "\n",
        "        if direct_match_topic > 1:\n",
        "            direct_match_topic = 10 * 1.5\n",
        "        else:\n",
        "            direct_match_topic =  10 * direct_match_topic\n",
        "\n",
        "        return topic_text_simi + keywrd_max + keywrd_avg + direct_match_keyword + direct_match_topic\n",
        "\n",
        "        \n",
        "\n",
        "    final_df['avaerage_score'] = final_df.apply(lambda x: word_avg(x['topic_text_similarity'],x['keyword_max'],x['keyword_avg'],x['direct_matching_keyword'],x['direct_matching_topic']),axis=1)\n",
        "\n",
        "    return final_df.to_dict()\n",
        "\n",
        "app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V-2yEDdXuAe",
        "outputId": "0ea64a11-0d12-459d-c5c4-518d7aa40279"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: ngrok: command not found\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://4f38-104-196-137-191.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [12/Nov/2022 17:25:22] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Nov/2022 17:25:22] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [12/Nov/2022 17:25:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hCmczhFHmhM_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8PUB7yy4t1Yt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6kJ-_kjt1Nz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4sxwgoGtt1FN"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}